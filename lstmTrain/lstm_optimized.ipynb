{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 优化后的LSTM股价预测模型\n",
        "# 所有必要的导入\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sqlite3\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 设备配置\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"使用设备: {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 数据加载和预处理函数\n",
        "def load_and_preprocess_data(db_path=\"../getTradeData/binance.db\", table_name=\"BTCUSDT\"):\n",
        "    \"\"\"加载数据并进行基本预处理\"\"\"\n",
        "    try:\n",
        "        connection = sqlite3.connect(db_path)\n",
        "        sql_query = f\"SELECT * FROM {table_name}\"\n",
        "        df = pd.read_sql_query(sql_query, connection)\n",
        "        connection.close()\n",
        "        \n",
        "        # 数据类型转换\n",
        "        numeric_columns = ['open', 'high', 'low', 'close', 'volume', \n",
        "                          'quote_asset_volume', 'taker_buy_base_asset_volume', \n",
        "                          'taker_buy_quote_asset_volume']\n",
        "        df[numeric_columns] = df[numeric_columns].astype(float)\n",
        "        \n",
        "        print(f\"数据加载成功，形状: {df.shape}\")\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f\"数据加载错误: {e}\")\n",
        "        return None\n",
        "\n",
        "# 加载数据\n",
        "df = load_and_preprocess_data()\n",
        "if df is not None:\n",
        "    print(\"前5行数据:\")\n",
        "    print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 优化的特征工程函数\n",
        "def calculate_technical_indicators(df):\n",
        "    \"\"\"计算技术指标，避免重复和冗余\"\"\"\n",
        "    # 基本技术指标\n",
        "    # RSI\n",
        "    delta = df['close'].diff()\n",
        "    gain = delta.where(delta > 0, 0)\n",
        "    loss = -delta.where(delta < 0, 0)\n",
        "    avg_gain = gain.rolling(window=14).mean()\n",
        "    avg_loss = loss.rolling(window=14).mean()\n",
        "    rs = avg_gain / avg_loss\n",
        "    df['rsi'] = 100 - (100 / (1 + rs))\n",
        "    \n",
        "    # EMA\n",
        "    df['ema_12'] = df['close'].ewm(span=12).mean()\n",
        "    df['ema_26'] = df['close'].ewm(span=26).mean()\n",
        "    \n",
        "    # MACD\n",
        "    df['macd'] = df['ema_12'] - df['ema_26']\n",
        "    df['macd_signal'] = df['macd'].ewm(span=9).mean()\n",
        "    df['macd_histogram'] = df['macd'] - df['macd_signal']\n",
        "    \n",
        "    # 移动平均线 (选择有代表性的周期)\n",
        "    df['sma_10'] = df['close'].rolling(window=10).mean()\n",
        "    df['sma_20'] = df['close'].rolling(window=20).mean()\n",
        "    \n",
        "    # 布林带\n",
        "    df['bb_middle'] = df['sma_20']\n",
        "    df['bb_std'] = df['close'].rolling(window=20).std()\n",
        "    df['bb_upper'] = df['bb_middle'] + 2 * df['bb_std']\n",
        "    df['bb_lower'] = df['bb_middle'] - 2 * df['bb_std']\n",
        "    \n",
        "    # 价格相对位置指标 (更有意义的特征)\n",
        "    df['price_to_sma10'] = df['close'] / df['sma_10']  # 相对比率而非差值\n",
        "    df['price_to_sma20'] = df['close'] / df['sma_20']\n",
        "    df['bb_position'] = (df['close'] - df['bb_lower']) / (df['bb_upper'] - df['bb_lower'])\n",
        "    \n",
        "    # 波动率\n",
        "    df['volatility'] = df['close'].rolling(window=10).std()\n",
        "    df['price_change'] = df['close'].pct_change()\n",
        "    \n",
        "    # 成交量相关指标\n",
        "    df['volume_ma'] = df['volume'].rolling(window=10).mean()\n",
        "    df['volume_ratio'] = df['volume'] / df['volume_ma']\n",
        "    \n",
        "    # 高低点指标\n",
        "    df['hl_ratio'] = (df['high'] - df['low']) / df['close']\n",
        "    df['oc_ratio'] = (df['close'] - df['open']) / df['open']\n",
        "    \n",
        "    print(\"技术指标计算完成\")\n",
        "    return df\n",
        "\n",
        "# 计算技术指标\n",
        "if df is not None:\n",
        "    df = calculate_technical_indicators(df)\n",
        "    print(f\"添加技术指标后的数据形状: {df.shape}\")\n",
        "    print(\"\\\\n特征列表:\")\n",
        "    print([col for col in df.columns if col not in ['open_time', 'close_time', 'symbol', 'interval']])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 数据预处理和数据集创建\n",
        "def prepare_dataset(df, sequence_length=30, train_ratio=0.8):\n",
        "    \"\"\"统一的数据集准备函数，避免重复代码\"\"\"\n",
        "    \n",
        "    # 选择输入特征（移除原始OHLC作为输入，因为它们也是输出目标）\n",
        "    feature_columns = [\n",
        "        'rsi', 'ema_12', 'ema_26', 'macd', 'macd_signal', 'macd_histogram',\n",
        "        'sma_10', 'sma_20', 'bb_upper', 'bb_lower', 'bb_position',\n",
        "        'price_to_sma10', 'price_to_sma20', 'volatility', 'price_change',\n",
        "        'volume_ratio', 'hl_ratio', 'oc_ratio'\n",
        "    ]\n",
        "    \n",
        "    # 输出目标\n",
        "    target_columns = ['open', 'high', 'low', 'close']\n",
        "    \n",
        "    # 处理缺失值\n",
        "    df_clean = df.dropna()\n",
        "    print(f\"清理缺失值后的数据形状: {df_clean.shape}\")\n",
        "    \n",
        "    # 准备特征和目标数据\n",
        "    features = df_clean[feature_columns].values\n",
        "    targets = df_clean[target_columns].values\n",
        "    \n",
        "    # 分别标准化特征和目标\n",
        "    feature_scaler = MinMaxScaler()\n",
        "    target_scaler = MinMaxScaler()\n",
        "    \n",
        "    features_scaled = feature_scaler.fit_transform(features)\n",
        "    targets_scaled = target_scaler.fit_transform(targets)\n",
        "    \n",
        "    # 创建序列数据\n",
        "    def create_sequences(features, targets, seq_length):\n",
        "        X, y = [], []\n",
        "        for i in range(seq_length, len(features)):\n",
        "            X.append(features[i-seq_length:i])\n",
        "            y.append(targets[i])\n",
        "        return np.array(X), np.array(y)\n",
        "    \n",
        "    X, y = create_sequences(features_scaled, targets_scaled, sequence_length)\n",
        "    \n",
        "    # 划分训练和测试集\n",
        "    split_index = int(len(X) * train_ratio)\n",
        "    \n",
        "    X_train, X_test = X[:split_index], X[split_index:]\n",
        "    y_train, y_test = y[:split_index], y[split_index:]\n",
        "    \n",
        "    print(f\"训练集形状: X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
        "    print(f\"测试集形状: X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
        "    \n",
        "    return (X_train, y_train, X_test, y_test, \n",
        "            feature_scaler, target_scaler, feature_columns, target_columns)\n",
        "\n",
        "# 准备数据集\n",
        "if df is not None:\n",
        "    (X_train, y_train, X_test, y_test, \n",
        "     feature_scaler, target_scaler, feature_columns, target_columns) = prepare_dataset(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 优化的数据集类\n",
        "class TimeSeriesDataset(Dataset):\n",
        "    \"\"\"优化的时间序列数据集类，支持动态加载\"\"\"\n",
        "    def __init__(self, X, y, device=None):\n",
        "        self.device = device if device else torch.device(\"cpu\")\n",
        "        # 避免一次性将所有数据移动到GPU，节省内存\n",
        "        self.X = torch.tensor(X, dtype=torch.float32)\n",
        "        self.y = torch.tensor(y, dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # 在需要时才移动到设备\n",
        "        return (self.X[idx].to(self.device), \n",
        "                self.y[idx].to(self.device))\n",
        "\n",
        "# 创建数据集和数据加载器\n",
        "train_dataset = TimeSeriesDataset(X_train, y_train, device)\n",
        "test_dataset = TimeSeriesDataset(X_test, y_test, device)\n",
        "\n",
        "# 使用更合理的批次大小\n",
        "batch_size = min(64, len(train_dataset) // 10)  # 自适应批次大小\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f\"批次大小: {batch_size}\")\n",
        "print(f\"训练批次数: {len(train_loader)}\")\n",
        "print(f\"测试批次数: {len(test_loader)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 优化的LSTM模型\n",
        "class OptimizedLSTM(nn.Module):\n",
        "    \"\"\"简化且更高效的LSTM模型\"\"\"\n",
        "    def __init__(self, input_size, hidden_size=64, num_layers=2, output_size=4, dropout=0.2):\n",
        "        super(OptimizedLSTM, self).__init__()\n",
        "        \n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        \n",
        "        # 简化架构：使用2层双向LSTM + 注意力机制\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=input_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=True,\n",
        "            dropout=dropout if num_layers > 1 else 0\n",
        "        )\n",
        "        \n",
        "        # 注意力机制\n",
        "        self.attention = nn.MultiheadAttention(\n",
        "            embed_dim=hidden_size * 2,\n",
        "            num_heads=8,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "        \n",
        "        # 输出层\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc1 = nn.Linear(hidden_size * 2, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "        \n",
        "        # 残差连接的投影层\n",
        "        self.projection = nn.Linear(input_size, output_size)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # LSTM层\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "        \n",
        "        # 注意力机制\n",
        "        attn_out, _ = self.attention(lstm_out, lstm_out, lstm_out)\n",
        "        \n",
        "        # 取最后一个时间步的输出\n",
        "        last_hidden = attn_out[:, -1, :]\n",
        "        \n",
        "        # 全连接层\n",
        "        out = self.dropout(last_hidden)\n",
        "        out = self.fc1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.dropout(out)\n",
        "        out = self.fc2(out)\n",
        "        \n",
        "        # 残差连接（使用输入的最后一个时间步）\n",
        "        residual = self.projection(x[:, -1, :])\n",
        "        out = out + residual\n",
        "        \n",
        "        return out\n",
        "\n",
        "# 创建模型\n",
        "input_size = len(feature_columns)\n",
        "model = OptimizedLSTM(\n",
        "    input_size=input_size,\n",
        "    hidden_size=64,\n",
        "    num_layers=2,\n",
        "    output_size=len(target_columns),\n",
        "    dropout=0.2\n",
        ").to(device)\n",
        "\n",
        "# 计算模型参数数量\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"模型结构:\")\n",
        "print(model)\n",
        "print(f\"\\\\n总参数数: {total_params:,}\")\n",
        "print(f\"可训练参数数: {trainable_params:,}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 训练配置和优化器\n",
        "class Config:\n",
        "    \"\"\"训练配置类\"\"\"\n",
        "    def __init__(self):\n",
        "        self.epochs = 100\n",
        "        self.learning_rate = 0.001\n",
        "        self.patience = 10  # 早停耐心值\n",
        "        self.min_delta = 1e-6  # 最小改善阈值\n",
        "        self.weight_decay = 1e-5  # L2正则化\n",
        "\n",
        "config = Config()\n",
        "\n",
        "# 损失函数和优化器\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=config.learning_rate, weight_decay=config.weight_decay)\n",
        "\n",
        "# 学习率调度器\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode='min', factor=0.5, patience=5, verbose=True, min_lr=1e-6\n",
        ")\n",
        "\n",
        "# 早停类\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=10, min_delta=1e-6):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.best_loss = float('inf')\n",
        "        \n",
        "    def __call__(self, val_loss):\n",
        "        if val_loss < self.best_loss - self.min_delta:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0\n",
        "            return False\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            return self.counter >= self.patience\n",
        "\n",
        "early_stopping = EarlyStopping(patience=config.patience, min_delta=config.min_delta)\n",
        "\n",
        "print(\"训练配置完成\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 优化的训练循环\n",
        "def train_model(model, train_loader, test_loader, criterion, optimizer, scheduler, early_stopping, config):\n",
        "    \"\"\"优化的训练函数，包含验证和早停\"\"\"\n",
        "    \n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    best_val_loss = float('inf')\n",
        "    \n",
        "    print(\"开始训练...\")\n",
        "    \n",
        "    for epoch in range(config.epochs):\n",
        "        # 训练阶段\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        train_batches = 0\n",
        "        \n",
        "        for batch_X, batch_y in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(batch_X)\n",
        "            loss = criterion(outputs, batch_y)\n",
        "            loss.backward()\n",
        "            \n",
        "            # 梯度裁剪防止梯度爆炸\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            \n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "            train_batches += 1\n",
        "        \n",
        "        avg_train_loss = train_loss / train_batches\n",
        "        train_losses.append(avg_train_loss)\n",
        "        \n",
        "        # 验证阶段\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_batches = 0\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            for batch_X, batch_y in test_loader:\n",
        "                outputs = model(batch_X)\n",
        "                loss = criterion(outputs, batch_y)\n",
        "                val_loss += loss.item()\n",
        "                val_batches += 1\n",
        "        \n",
        "        avg_val_loss = val_loss / val_batches\n",
        "        val_losses.append(avg_val_loss)\n",
        "        \n",
        "        # 学习率调度\n",
        "        scheduler.step(avg_val_loss)\n",
        "        \n",
        "        # 保存最佳模型\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "        \n",
        "        # 每10个epoch打印一次进度\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            current_lr = optimizer.param_groups[0]['lr']\n",
        "            print(f'Epoch [{epoch+1}/{config.epochs}] - '\n",
        "                  f'训练损失: {avg_train_loss:.6f} - '\n",
        "                  f'验证损失: {avg_val_loss:.6f} - '\n",
        "                  f'学习率: {current_lr:.8f}')\n",
        "        \n",
        "        # 早停检查\n",
        "        if early_stopping(avg_val_loss):\n",
        "            print(f'\\\\n早停在epoch {epoch+1}，最佳验证损失: {best_val_loss:.6f}')\n",
        "            break\n",
        "    \n",
        "    print(f'\\\\n训练完成！最佳验证损失: {best_val_loss:.6f}')\n",
        "    \n",
        "    # 加载最佳模型\n",
        "    model.load_state_dict(torch.load('best_model.pth'))\n",
        "    \n",
        "    return train_losses, val_losses\n",
        "\n",
        "# 开始训练\n",
        "train_losses, val_losses = train_model(\n",
        "    model, train_loader, test_loader, criterion, \n",
        "    optimizer, scheduler, early_stopping, config\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 模型评估和可视化\n",
        "def evaluate_model(model, test_loader, target_scaler, target_columns):\n",
        "    \"\"\"评估模型性能\"\"\"\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    actuals = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch_X, batch_y in test_loader:\n",
        "            outputs = model(batch_X)\n",
        "            predictions.append(outputs.cpu().numpy())\n",
        "            actuals.append(batch_y.cpu().numpy())\n",
        "    \n",
        "    # 合并所有批次的预测和实际值\n",
        "    predictions = np.concatenate(predictions, axis=0)\n",
        "    actuals = np.concatenate(actuals, axis=0)\n",
        "    \n",
        "    # 反标准化\n",
        "    predictions_rescaled = target_scaler.inverse_transform(predictions)\n",
        "    actuals_rescaled = target_scaler.inverse_transform(actuals)\n",
        "    \n",
        "    # 计算评估指标\n",
        "    mse = mean_squared_error(actuals_rescaled, predictions_rescaled)\n",
        "    rmse = np.sqrt(mse)\n",
        "    mae = mean_absolute_error(actuals_rescaled, predictions_rescaled)\n",
        "    \n",
        "    # 计算MAPE (平均绝对百分比误差)\n",
        "    mape = np.mean(np.abs((actuals_rescaled - predictions_rescaled) / actuals_rescaled)) * 100\n",
        "    \n",
        "    print(\"\\n=== 模型评估结果 ===\")\n",
        "    print(f\"均方误差 (MSE): {mse:.4f}\")\n",
        "    print(f\"均方根误差 (RMSE): {rmse:.4f}\")\n",
        "    print(f\"平均绝对误差 (MAE): {mae:.4f}\")\n",
        "    print(f\"平均绝对百分比误差 (MAPE): {mape:.2f}%\")\n",
        "    \n",
        "    # 按每个目标变量计算误差\n",
        "    print(\"\\n各目标变量的RMSE:\")\n",
        "    for i, col in enumerate(target_columns):\n",
        "        col_rmse = np.sqrt(mean_squared_error(actuals_rescaled[:, i], predictions_rescaled[:, i]))\n",
        "        print(f\\\"{col}: {col_rmse:.4f}\\\")\n",
        "    \n",
        "    return predictions_rescaled, actuals_rescaled\n",
        "\n",
        "# 评估模型\n",
        "predictions, actuals = evaluate_model(model, test_loader, target_scaler, target_columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 优化总结\n",
        "\n",
        "## 原始代码的主要问题：\n",
        "\n",
        "### 1. **重复的代码块**\n",
        "- Cell 23和25中数据集创建代码完全重复\n",
        "- 多次导入相同的包（pandas等）\n",
        "\n",
        "### 2. **冗余的特征**\n",
        "- 过多相关性高的移动平均线（3,6,12,20周期）\n",
        "- 重复的布林带计算（bollinger_middle就是sma_20）\n",
        "- 一些特征信息量低（如直接的差值特征）\n",
        "\n",
        "### 3. **模型架构过度复杂**\n",
        "- 使用4层LSTM容易过拟合\n",
        "- MaxPool1d对时间序列意义不大\n",
        "- 没有残差连接和注意力机制\n",
        "\n",
        "### 4. **训练过程不完善**\n",
        "- 缺少早停机制\n",
        "- 没有学习率调度\n",
        "- 缺少梯度裁剪\n",
        "- 只打印最后一个batch的损失\n",
        "\n",
        "## 优化后的改进：\n",
        "\n",
        "### 1. **代码结构优化**\n",
        "- 函数化所有主要操作\n",
        "- 消除重复代码\n",
        "- 添加错误处理\n",
        "\n",
        "### 2. **特征工程优化**\n",
        "- 使用相对比率代替绝对差值\n",
        "- 减少冗余特征，保留信息量高的指标\n",
        "- 添加成交量和波动率相关特征\n",
        "\n",
        "### 3. **模型架构改进**\n",
        "- 使用2层双向LSTM + 注意力机制\n",
        "- 添加残差连接提升训练稳定性\n",
        "- 合理的dropout设置\n",
        "\n",
        "### 4. **训练优化**\n",
        "- 早停机制防止过拟合\n",
        "- 自适应学习率调度\n",
        "- 梯度裁剪防止梯度爆炸\n",
        "- 完整的验证循环和模型保存\n",
        "\n",
        "### 5. **评估改进**\n",
        "- 多种评估指标（MSE, RMSE, MAE, MAPE）\n",
        "- 分别计算各目标变量的误差\n",
        "- 反标准化后的真实值评估\n",
        "\n",
        "这样的优化应该能显著提升模型性能和训练效率。\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
